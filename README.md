# MAGIC-VQA: Multimodal And Grounded Inference with Commonsense Knowledge for Visual Question Answering

<div align="center">
      <h2>Authors</h2>
      <p>
        <strong>Shuo Yang</strong><sup>1</sup>,  
        <strong>Soyeon Caren Han</strong><sup>1,*</sup>,  
        <strong>Siwen Luo</strong><sup>2</sup>,  
        <strong>Eduard Hovy</strong><sup>1</sup>
        <br>
        <em>* Corresponding Author</em>
      </p>
</div>

<div align="center">
    <p>
        <sup>1</sup> The University of Melbourne
        <sup>2</sup> The University of Western Australia
    </p>
</div>

<div align="center">
<p>
      <sup>1</sup> <a href="mailto:shuo.yang.3@unimelb.edu.au">shuo.yang.3@unimelb.edu.au</a> 
      <sup>2</sup> <a href="mailto:caren.han@unimelb.edu.au">caren.han@unimelb.edu.au</a>,  
</p>
</div>

<div align="center">

<strong style="font-size: 18px;">Accepted by the 2025 Association for Computational Linguistics: ACL 2025</strong> <br>
    <strong style="font-size: 18px;">(ACL 2025)</strong>
</div>
